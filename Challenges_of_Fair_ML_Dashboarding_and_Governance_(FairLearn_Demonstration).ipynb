{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Challenges of Fair ML - Dashboarding and Governance (FairLearn Demonstration)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMG0hMSKLhpo1BtIpxEHzMj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daanknoope/DSFC-2021-FairLearn-Demo/blob/main/Challenges_of_Fair_ML_Dashboarding_and_Governance_(FairLearn_Demonstration).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO1h0rNgkHk_"
      },
      "source": [
        "# Challenges of Fair ML - Dashboarding and Governance\n",
        "Demonstration of how to use FairLearn for the Data Science in Finance conference, 2021.\n",
        "\n",
        "This demonstration was created to be run in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8ofsL9wkOXk"
      },
      "source": [
        "## Loading Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_JX6G5jkUaw"
      },
      "source": [
        "First we need to install `raiwidgets` to be able to use the fairlearn dashboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B2phZXGK71P"
      },
      "source": [
        "!pip install -q raiwidgets \n",
        "!pip install -q fairlearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5-JMxCzkhcx"
      },
      "source": [
        "Next we load the packages we require."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x26YUvsyKwOy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezS4O43BkuCz"
      },
      "source": [
        "Finally, we download the heart disease dataeset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gIkFXfykzAF"
      },
      "source": [
        "!wget -O healthcare-dataset-stroke-data.csv https://gist.githubusercontent.com/aishwarya8615/d2107f828d3f904839cbcb7eaa85bd04/raw/cec0340503d82d270821e03254993b6dede60afb/healthcare-dataset-stroke-data.csv "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVo9zfiKlWKz"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-ztASF9lXlr"
      },
      "source": [
        "Next, we can take a look at our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1PgyGniLCeM"
      },
      "source": [
        "stroke_data_df = pd.read_csv('healthcare-dataset-stroke-data.csv',index_col='id').dropna()\n",
        "stroke_data_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3h8-8D-lcDI"
      },
      "source": [
        "Let's see look at the distribution of stroke cases in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DsgAQPklrRF"
      },
      "source": [
        "stroke_data_df['stroke'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n78vc-eDl78e"
      },
      "source": [
        "Gender is often a sensitive variable. Let's see how it is distributed in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhlMIb5ULouY"
      },
      "source": [
        "stroke_data_df['gender'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zcoGlz0mEiQ"
      },
      "source": [
        "So we have more data about female patients than male patients. What is the relationship between getting a stroke and gender?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVtLk4fJmVPt"
      },
      "source": [
        "stroke_data_df.groupby('stroke').gender.value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-i9vZb-nsOC"
      },
      "source": [
        "stroke_data_df.groupby('smoking_status').gender.value_counts().unstack(0).plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eKdTnbQoAkc"
      },
      "source": [
        "stroke_data_df.groupby('smoking_status').stroke.value_counts().unstack(0).plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7s6WCKFYHX8"
      },
      "source": [
        "\n",
        "sns.displot(data=stroke_data_df, x='bmi', hue='gender')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMpTbxKhpjRL"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEZ2y3_xDG7y"
      },
      "source": [
        "We need to first set apart the sensitive features which we have in our dataset. These need to be placed in a data frame, which FairLearn is going to use to calculate fairness metrics with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIaYELUY3mMQ"
      },
      "source": [
        "sensitive_features = ['gender', 'Residence_type']\n",
        "sensitive_features_df = stroke_data_df[sensitive_features]\n",
        "sensitive_features_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpeQo6WEDXev"
      },
      "source": [
        "After that we can encode our categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLZvCIWK3wZT"
      },
      "source": [
        "stroke_data_encoded_df = pd.get_dummies(stroke_data_df.drop(sensitive_features, axis=1))\n",
        "\n",
        "stroke_data_encoded_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZZSh6JXDd-x"
      },
      "source": [
        "Having fully prepared our data, we can now split it into the train and test set. Note that we also include the `sensitive_features` here, since they need to be split in the same way as the train and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhTrCXBV3fDV"
      },
      "source": [
        "X = stroke_data_encoded_df.loc[ : , stroke_data_encoded_df.columns != 'stroke']\n",
        "y = stroke_data_encoded_df.loc[: ,'stroke']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test, sensitive_features_train, sensitive_features_test = train_test_split(X, y, sensitive_features_df, test_size=0.3, random_state=1, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w1HMUjzDx7t"
      },
      "source": [
        "Finally we can train a model on the dataset. Here we'll use a logistic regression, for no particular reason."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-4pQ5gK5N81"
      },
      "source": [
        "model = LogisticRegression(class_weight='balanced', random_state=1, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckQ3kQy45pXw"
      },
      "source": [
        "list(zip(X_train.columns,model.coef_[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaKcsdsKD46d"
      },
      "source": [
        "We can then see an accuracy of 0.71 in the classification report on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJnlrUn7kCf"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YLc4XkWD-dH"
      },
      "source": [
        "This does not help us understand the differences between the sensitive groups we have however. We have an average of 0.71, but this might be different throughout the different groups. So let's look further into that with FairLearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-7BsJ3WMwIw"
      },
      "source": [
        "from raiwidgets import FairnessDashboard\n",
        "\n",
        "# A_test contains your sensitive features (e.g., age, binary gender)\n",
        "# y_true contains ground truth labels\n",
        "# y_pred contains prediction labels\n",
        "\n",
        "FairnessDashboard(sensitive_features=sensitive_features_test,\n",
        "                  y_true=y_test,\n",
        "                  y_pred=y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}